<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="github-pandoc.css" type="text/css" />
</head>
<body>
<h1 id="list-of-referenced-papers">List of Referenced Papers</h1>
<ul>
<li><p>Kingma, D. P., &amp; Ba, J. L. (2015). Adam: a Method for Stochastic Optimization. International Conference on Learning Representations, 1â€“13.</p></li>
<li><p>Xavier Glorot and Yoshua Bengio (2010): Understanding the difficulty of training deep feedforward neural networks. International conference on artificial intelligence and statistics.</p></li>
</ul>
<h1 id="list-of-useful-blogs">List of useful Blogs</h1>
<ul>
<li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/"><strong>colah's</strong> blog on LSTMs</a></li>
<li><a href="http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/"><strong>WildML</strong> on CNNs for Text</a></li>
<li><a href="http://www.foldl.me/2014/glove-python/"><strong>foldl</strong> on GloVe</a></li>
<li><a href="http://sebastianruder.com/optimizing-gradient-descent/index.html"><strong>Sebastian Ruder</strong> on gradient descent</a></li>
</ul>
</body>
</html>
