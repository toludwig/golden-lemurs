<h1 id="convolutional-neural-networks">Convolutional Neural Networks</h1>
<p>Convolutional neural networks are actually known to be very successful visual classifiers. However, they can also be applied in Computational Linguistics for semantic analysis of text. In our case, we want to learn the the topic of a Repository by 'reading' its README.</p>
<h2 id="background-of-convolutions-in-computer-vision">Background of convolutions in Computer Vision</h2>
<p>If you want to perform object recognition in visual images, probably you want to be <strong>invariant</strong> with respect to the size, orientation and the location of the object within the image. Also it makes (biologically) sense to start from recognized edges and abstract (<strong>compose</strong>) to shapes and objects.</p>
<p>All these are characteristic functions of <strong>CNN</strong>s and are achieved by so-called <strong>convolutions</strong> and <strong>pooling</strong>. A convolution is basically a filter (aka. kernel) sliding over a whole image, like in the following nice simulation [<a href="http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution">1</a>]:</p>
<div class="figure">
<img src="assets/docs/img/Convolution_schematic.gif" />

</div>
<p>By applying this with several filters you obtain multiple Convolutional Layers extracting different features of the image. Further location invariance is added by Pooling where some feature information is thrown away again. For example take max-pooling: there you just take maximum of your neighbours at each pixel [<a href="https://en.wikipedia.org/wiki/Convolutional_neural_network#/media/File:Max_pooling.png">2</a>].</p>
<div class="figure">
<img src="assets/docs/img/Max_pooling.png" />

</div>
<p>While these concepts are very vivid in the case of images, they are not yet for language, let us see...</p>
<h2 id="word-vectors-and-the-intuition-behind-them">Word Vectors and the intuition behind them</h2>
<p>Linguists don't work with images but with corpuses, i.e. huge amounts of real world text. Why not think of words as vectors (coordinate lists) within the <em>n</em>-dimensional corpus space? Note that the space would be a discrete one, it contains only its words but nothing 'in between'. However, what we want is a continuous vector space of words. Also, we want it to have substantially less dimensions (note that <em>n</em> is the size of a typical big data corpus). We want real-valued vectors, something like:</p>
<div class="figure">
<img src="assets/docs/img/word_vector_space.png" />

</div>
<p>This reduction of dimensionality can be achieved using modern variants of the classical bag-of-words model called <strong>word embeddings</strong>. What is done is basically a packing of cooccurring words in the same 'bag'. The so obtained vectors show very cool (vector-space) behaviour:</p>
<pre><code>king - man + woman ~ queen
dog + big + dangerous ~ bulldog</code></pre>
<p>Here is another fancy picture that (produced by tSNE) showing the vector space [<a href="http://www.cs.toronto.edu/~nitish/csc321/tsne.png">3</a>]:</p>
<div class="figure">
<img src="assets/docs/img/tsne.png" />

</div>
<p>But, lo and behold, there are pretrained datasets around that offer exactly this! The one we are using is generated by Google using its famous <em>word2vec</em> algorithm. It is trained on the whole <strong>Google News</strong> corpus (<em>n</em>=100 billion) and is <a href="https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit">available here</a>. The model contains 300-dimensional vectors for 3 million words and phrases. This means, if you do a lookup for a word in the dataset you will get a list of 300 real numbers indicating the position of the word within the vector space.</p>
<p>For further theoretical explanation see <a href="http://arxiv.org/pdf/1310.4546.pdf">the original paper</a> by Google's group around Thomas Mikolov. You may also want to check <a href="http://www.foldl.me/2014/glove-python/">this Blog post</a> on GloVe, a similiar vector database (which we chose first, but failed to download).</p>
<h2 id="data-preprocessing">Data preprocessing</h2>
<p>We work with the first <code>300</code> words of the README and the first <code>400</code> words of the commits (concatenated from multiple commits). If either of both texts is not long enough, we fill the vector with padding words (<code>\pad\</code>).</p>
<p>Now, if we want to apply this to extract (hopefully) the topic of the repository, we need to be aware of two things:</p>
<p>First, the repo might not have a README at all (or, say it is empty). In this case classification seems to be futile, but nethertheless it tells us something. We observed for example that homework repos often lack a README (for obvious reasons). <em>Solution</em>: we provide an empty vector (filled with 300 pads) as a dummy for classification.</p>
<p>Second, texts are cluttered by punctuation signs and other 'text mess'. After we applied the word tokenizer to the texts, these are still sticking at the words. However, there are word-vectors for those signs so we do not need/want to extract them entirely. <em>Solution</em>: parse and split those signs from the words (see <code>classification.Data.clean_str</code>)</p>
<h2 id="our-cnn-for-word-vectors">Our CNN for Word Vectors</h2>
<p>Now for the actual neural net. We construct a Convolutional Neural Network of a single convolutional and following pooling layer. Its topology looks like this [<a href="http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/">4</a>]:</p>
<div class="figure">
<img src="assets/docs/img/cnn_topology.png" />

</div>
<p>The size of the input matrix is <code>300</code> words of the mentioned vector dimensionality 300.</p>
<p>For the convolutional layer, we use one-dimensional filters over multiple words with sizes of <em>k</em> out of <code>[3, 4, 5]</code>. For each filter we have <code>164</code> instances of initially random weights which are learned in the training. The strides with which the filters are sliding equal <code>1</code> for all filter sizes, hence they are of course overlapping. After we applied these convolutions one layer of max pooling follows.</p>
<p>Then we have all the features extracted and can learn on those. This is done by the last fully connected layer with <code>100</code> hidden units.</p>
<h2 id="our-cnn-for-commit-messages">Our CNN for Commit messages</h2>
<p>The CNN for Commit messages looks basically the same with the only difference that the input size is <code>400</code> words and we use <code>200</code> filters.</p>
<p><a href="/docs/ffn">Previous page: Feed-forward network</a><br />
<a href="/docs/rnn">Next page: Recurrent networks</a><br />
<a href="/docs/intro">Table of Contents</a></p>
