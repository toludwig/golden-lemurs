<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="github-pandoc.css" type="text/css" />
</head>
<body>
<h1 id="a-convolutional-net-cnn-for-text-analysis">A Convolutional Net (CNN) for text analysis</h1>
<p>Convolutional neural networks are actually known to be very successful visual classifiers. However, they can also be applied in Computational Linguistics for semantic analysis of text. In our case, we want to learn the the topic of a Repository by 'reading' its README.</p>
<h1 id="background-of-convolutions-in-computer-vision">Background of convolutions in Computer Vision</h1>
<p>If you want to perform object recognition in visual images, probably you want to be <strong>invariant</strong> with respect to the size, orientation and the location of the object within the image. Also it makes (biologically) sense to start from recognized edges and abstract (<strong>compose</strong>) to shapes and objects.</p>
<p>All these are characteristic functions of <strong>CNN</strong>s and are achieved by so-called <strong>convolutions</strong> and <strong>pooling</strong>. A convolution is basically a filter (aka. kernel) sliding over a whole image, like in the following nice simulation [<a href="http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution">1</a>]:</p>
<div class="figure">
<img src="assets/docs/img/Convolution_schematic.gif" alt="picture of convolution" />
<p class="caption">picture of convolution</p>
</div>
<p>By applying this with several filters you obtain multiple Convolutional Layers extracting different features of the image. Further location invariance is added by Pooling where some feature information is thrown away again. For example take max-pooling: there you just take maximum of your neighbours at each pixel [<a href="https://en.wikipedia.org/wiki/Convolutional_neural_network#/media/File:Max_pooling.png">2</a>].</p>
<div class="figure">
<img src="assets/docs/img/Max_pooling.png" alt="picture of pooling" />
<p class="caption">picture of pooling</p>
</div>
<p>While these concepts are very vivid in the case of images, they are not yet for language, let us see...</p>
<h1 id="word-vectors-and-the-intuition-behind-them">Word Vectors and the intuition behind them</h1>
<p>Linguists don't work with images but with corpuses, i.e. huge amounts of real world text. Why not think of words as vectors (coordinate lists) within the <em>n</em>-dimensional corpus space? Note that the space would be a discrete one, it contains only its words but nothing 'in between'. However, what we want is a continuous vector space of words. Also, we want it to have substantially less dimensions (note that <em>n</em> is the size of a typical big data corpus). We want real-valued vectors, something like:</p>
<div class="figure">
<img src="assets/docs/img/word_vector_space.png" alt="picture of vectors in space" />
<p class="caption">picture of vectors in space</p>
</div>
<p>This reduction of dimensionality can be achieved using modern variants of the classical bag-of-words model called <strong>word embeddings</strong>. What is done is basically a packing of cooccurring words in the same 'bag'. The so obtained vectors show very cool (vector-space) behaviour:</p>
<pre><code>king - man + woman ~ queen
dog + big + dangerous ~ bulldog</code></pre>
<p>But, lo and behold, there are pretrained datasets around that offer exactly this! The one we are using is generated by Google using its famous <em>word2vec</em> algorithm. It is trained on the whole <strong>Google News</strong> corpus (<em>n</em>=100 billion) and is <a href="https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit">available here</a>.</p>
<p>For further theoretical explanation see <a href="http://arxiv.org/pdf/1310.4546.pdf">the original paper</a> by Google's group around Thomas Mikolov. You may also want to check <a href="http://www.foldl.me/2014/glove-python/">this Blog post</a> on GloVe, a similiar vector database (which we chose first, but failed to download).</p>
<h1 id="data-preprocessing">Data preprocessing</h1>
<p>The Google model we are using contains 300-dimensional vectors for 3 million words and phrases. This means, if you do a lookup for a word in the dataset you will get a list of 300 real numbers indicating the position of the word within the vector space.</p>
<p>Now, if we want to apply this on a README to extract (hopefully) the topic of the repository, we need to be aware of two things:</p>
<ol style="list-style-type: decimal">
<li>First, the repo might not have a README at all (or, say it is empty). In this case classification seems to be futile, but nethertheless it tells us something. We observed, for example that homework repos often lack a README (for obvious reasons).
<ul>
<li>Solution: we provide an empty vector (filled with 300 zeros) as a dummy for classification.</li>
</ul></li>
<li>Second, texts are cluttered by punctuation signs and other 'text mess'. After we applied a tokenizer to the README text, these are sticking at our learning input. However, there are word-vectors for those signs so we do not need/want to extract them entirely.
<ul>
<li>Solution: parse and split those signs from the words (see <code>classification.Data.clean_str</code>)</li>
</ul></li>
</ol>
<h1 id="our-cnn-for-word-vectors">Our CNN for Word Vectors</h1>
<p>Now for the actual neural net. We construct a Convolutional Neural Network of multiple convolutional and pooling layers. Its topology looks like this [<a href="http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/">3</a>]:</p>
<div class="figure">
<img src="assets/docs/img/cnn_topology.png" alt="picture of cnn topology" />
<p class="caption">picture of cnn topology</p>
</div>
<p>The size of the input matrix is 300 words of the mentioned dimensionality 300.</p>
<p>For the convolutional layer, we use one-dimensional filters (because we operate on vectors) with sizes of <em>k</em> out of [3, 4, 5, 6]. For each filter we have 164 instances of initially random weights which are learned in the training, depicted here for <em>k</em>=3:</p>
<div class="figure">
<img src="assets/docs/img/filter_matrix.png" alt="picture of filter matrix" />
<p class="caption">picture of filter matrix</p>
</div>
<p>The strides with which the filters are sliding equal 1 for all filter sizes, hence they are of course overlapping.</p>
<p>After we applied these convolutions one layer of pooling follows.</p>
<h1 id="our-cnn-for-commit-messages">Our CNN for Commit messages</h1>
</body>
</html>
